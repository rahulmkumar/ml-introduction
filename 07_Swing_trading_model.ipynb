{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "\n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.learning_curve import validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Sequential Backward Selection algorithm below has been taken from:\n",
    "Python Machine Learning - By Sebastian Raschka - Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=self.test_size,\n",
    "                             random_state=self.random_state)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, \n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, \n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'data/price_data.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Features are F1 through F34\n",
    "# Labels are RET5, RET10, RET15, RET20, RET25, RET30\n",
    "\n",
    "X = data.loc[:,'F1':'F34']\n",
    "y5 = data.loc[:,'RET5']\n",
    "y10 = data.loc[:,'RET10']\n",
    "y15 = data.loc[:,'RET15']\n",
    "y20 = data.loc[:,'RET20']\n",
    "y25 = data.loc[:,'RET25']\n",
    "y30 = data.loc[:,'RET30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y5.head(5)\n",
    "#y10.head(5)\n",
    "#y15.head(5)\n",
    "#y20.head(5)\n",
    "#y25.head(5)\n",
    "y30.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y5.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we plot histograms for each return label we can see that all the returns are approximately normally distributed aroung 0. We can also see that this stock in particular has a positive skew. This conforms with the upward bias in the stock market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 8, 8\n",
    "y5.hist()\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('5 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y10.hist()\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('10 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y15.hist()\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('15 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y20.hist()\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('20 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y25.hist()\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('25 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y30.hist()\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('30 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 15, 8\n",
    "fig, axes = plt.subplots(2,3, sharex=False, sharey=False)\n",
    "\n",
    "axes[0,0].hist(y5)\n",
    "axes[0,0].set_title('5 Day Return', fontsize=15)\n",
    "\n",
    "axes[0,1].hist(y10)\n",
    "axes[0,1].set_title('10 Day Return', fontsize=15)\n",
    "\n",
    "axes[0,2].hist(y15)\n",
    "axes[0,2].set_title('15 Day Return', fontsize=15)\n",
    "\n",
    "axes[1,0].hist(y20)\n",
    "axes[1,0].set_title('20 Day Return', fontsize=15)\n",
    "\n",
    "axes[1,1].hist(y25)\n",
    "axes[1,1].set_title('25 Day Return', fontsize=15)\n",
    "\n",
    "axes[1,2].hist(y30)\n",
    "axes[1,2].set_title('30 Day Return', fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1\n",
    "In the first phase of model building we will start with the simplest label grouping. We will separate our labels into either positive, or negative returns. This will give us two classes with approximately equal class distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y5.columns = ['RET']\n",
    "y10.columns = ['RET']\n",
    "y15.columns = ['RET']\n",
    "y20.columns = ['RET']\n",
    "y25.columns = ['RET']\n",
    "y30.columns = ['RET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_class(row):\n",
    "    if row < 0.00:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y5_b = pd.Series(index=y5.index)\n",
    "y10_b = pd.Series(index=y5.index)\n",
    "y15_b = pd.Series(index=y5.index)\n",
    "y20_b = pd.Series(index=y5.index)\n",
    "y25_b = pd.Series(index=y5.index)\n",
    "y30_b = pd.Series(index=y5.index)\n",
    "\n",
    "y5_b = y5.apply(binary_class)\n",
    "y10_b = y10.apply(binary_class)\n",
    "y15_b = y15.apply(binary_class)\n",
    "y20_b = y20.apply(binary_class)\n",
    "y25_b = y25.apply(binary_class)\n",
    "y30_b = y30.apply(binary_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y25_b.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 8, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the binary classification results, we can see that separating the class labels based on negative and positive returns, gives us an approximately equal distribution for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y5_b.hist()\n",
    "plt.xlabel('Negative or Positive Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('Binary Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2\n",
    "In this phase we will increase the number of boundaries from one to two. From a trading standpoint, we want to stay away from trades that return close to 0% return. We do want to identify trades that have substantial return.\n",
    "\n",
    "We can define substantial return as > 2% or 0.02 or < -2% or -0.02\n",
    "Class boundaries:\n",
    "label 0: <=-0.02\n",
    "label 1: >-0.02 and < 0.02\n",
    "label 2: >= 0.02\n",
    "\n",
    "Another way to find out what the boundary should be is to look at the class distributions that result from a particular boundary. The boundary can then be changed to ensure that the distribution becomes approximately equal for all classes. You may find that you have to use different boundaries for different returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_return_class(row, neg_cutoff, pos_cutoff):\n",
    "    if row <= neg_cutoff:\n",
    "        return 0\n",
    "    elif row > neg_cutoff and row < pos_cutoff:\n",
    "        return 1\n",
    "    elif row >= pos_cutoff:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y5_t = pd.Series(index=y5.index)\n",
    "y10_t = pd.Series(index=y5.index)\n",
    "y15_t = pd.Series(index=y5.index)\n",
    "y20_t = pd.Series(index=y5.index)\n",
    "y25_t = pd.Series(index=y5.index)\n",
    "y30_t = pd.Series(index=y5.index)\n",
    "\n",
    "y5_t = y5.apply(update_return_class, args=(-0.02, 0.02))\n",
    "y10_t = y10.apply(update_return_class, args=(-0.03, 0.03))\n",
    "y15_t = y15.apply(update_return_class, args=(-0.05, 0.05))\n",
    "y20_t = y20.apply(update_return_class, args=(-0.05, 0.05))\n",
    "y25_t = y25.apply(update_return_class, args=(-0.05, 0.07))\n",
    "y30_t = y30.apply(update_return_class, args=(-0.05, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y5_t.hist()\n",
    "plt.xlabel('Trinary Classification Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('5 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y10_t.hist()\n",
    "plt.xlabel('Trinary Classification Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('10 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y15_t.hist()\n",
    "plt.xlabel('Trinary Classification Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('15 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y20_t.hist()\n",
    "plt.xlabel('Trinary Classification Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('20 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y25_t.hist()\n",
    "plt.xlabel('Trinary Classification Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('25 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y30_t.hist()\n",
    "plt.xlabel('Trinary Classification Return')\n",
    "plt.ylabel('# of samples')\n",
    "plt.title('30 Day Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 15, 8\n",
    "fig, axes = plt.subplots(2,3, sharex=False, sharey=False)\n",
    "\n",
    "axes[0,0].hist(y5_t)\n",
    "axes[0,0].set_title('5 Day Return', fontsize=15)\n",
    "\n",
    "axes[0,1].hist(y10_t)\n",
    "axes[0,1].set_title('10 Day Return', fontsize=15)\n",
    "\n",
    "axes[0,2].hist(y15_t)\n",
    "axes[0,2].set_title('15 Day Return', fontsize=15)\n",
    "\n",
    "axes[1,0].hist(y20_t)\n",
    "axes[1,0].set_title('20 Day Return', fontsize=15)\n",
    "\n",
    "axes[1,1].hist(y25_t)\n",
    "axes[1,1].set_title('25 Day Return', fontsize=15)\n",
    "\n",
    "axes[1,2].hist(y30_t)\n",
    "axes[1,2].set_title('30 Day Return', fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Validation Strategy\n",
    "We will be using multi-pronged testing strategy\n",
    "1) Use k-fold cross-validation\n",
    "2) Use continuous samples as training data and test on future data\n",
    "3) Use sliding window continuous training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X5b_train, X5b_validation, Y5b_train, Y5b_validation = cross_validation.train_test_split(X, y5_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X10b_train, X10b_validation, Y10b_train, Y10b_validation = cross_validation.train_test_split(X, y10_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X15b_train, X15b_validation, Y15b_train, Y15b_validation = cross_validation.train_test_split(X, y15_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X20b_train, X20b_validation, Y20b_train, Y20b_validation = cross_validation.train_test_split(X, y20_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X25b_train, X25b_validation, Y25b_train, Y25b_validation = cross_validation.train_test_split(X, y25_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X30b_train, X30b_validation, Y30b_train, Y30b_validation = cross_validation.train_test_split(X, y30_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "\n",
    "X5t_train, X5t_validation, Y5t_train, Y5t_validation = cross_validation.train_test_split(X, y5_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X10t_train, X10t_validation, Y10t_train, Y10t_validation = cross_validation.train_test_split(X, y10_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X15t_train, X15t_validation, Y15t_train, Y15t_validation = cross_validation.train_test_split(X, y15_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X20t_train, X20t_validation, Y20t_train, Y20t_validation = cross_validation.train_test_split(X, y20_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X25t_train, X25t_validation, Y25t_train, Y25t_validation = cross_validation.train_test_split(X, y25_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X30t_train, X30t_validation, Y30t_train, Y30t_validation = cross_validation.train_test_split(X, y30_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate Algorithms\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X10b_train)\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X10b_train, Y10b_train)\n",
    "Y_pred = xgb.predict(X10b_validation)\n",
    "plot_importance(xgb)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "xgb = XGBClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X10b_train_std = stdsc.fit_transform(X10b_train)\n",
    "X10b_test_std = stdsc.transform(X10b_validation)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rfecv = RFECV(estimator=et, step=1, cv=StratifiedKFold(y10_b, n_folds=2, random_state=seed), scoring='accuracy')\n",
    "rfecv = RFECV(estimator=et, step=1, scoring='accuracy')\n",
    "#print(len(X10b_train_std))\n",
    "#print(len(Y10b_train))\n",
    "\n",
    "rfecv.fit(X10b_train_std,Y10b_train)\n",
    "rfe = RFE(estimator=et, step=1)\n",
    "rfe.fit(X10b_train_std,Y10b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('# of selected features with CV: %i' %rfecv.n_features_)\n",
    "print('Mask of selected features with CV: %s' %rfecv.support_)\n",
    "print('Selected features ranking: %s' %rfecv.ranking_)\n",
    "print('CV scores: %s' %rfecv.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Original number of features is %s' % X.shape[1])\n",
    "print(\"RFE final number of features : %d\" % rfe.n_features_)\n",
    "print(\"RFECV final number of features : %d\" % rfecv.n_features_)\n",
    "print('')\n",
    "\n",
    "import numpy as np\n",
    "g_scores = rfecv.grid_scores_\n",
    "indices = np.argsort(g_scores)[::-1]\n",
    "print('Printing RFECV results:')\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. Number of features: %d; Grid_Score: %f\" % (f + 1, indices[f]+1, g_scores[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rfecv.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rfecv.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for selected, feature in zip(rfecv.support_, X.columns):\n",
    "    if selected == True:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB', AdaBoostClassifier())])))\n",
    "ensembles.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingClassifier())])))\n",
    "ensembles.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF', RandomForestClassifier())])))\n",
    "ensembles.append(('ScaledET', Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesClassifier())])))\n",
    "ensembles.append(('ScaledXGB', Pipeline([('Scaler', StandardScaler()),('XGB', XGBClassifier())])))\n",
    "results = []\n",
    "names = []\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "for name, model in ensembles:\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "model = Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesClassifier())])\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, X, y5_b, cv=kfold, n_jobs=1, train_sizes=np.linspace(.1,1.0,5))\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.grid()\n",
    "plt.fill_between(train_sizes, train_scores_mean-train_scores_std, train_scores_mean+train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean-test_scores_std, test_scores_mean+test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training Score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-Validation Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_validation)\n",
    "    \n",
    "et = ExtraTreesClassifier()\n",
    "\n",
    "# selecting features\n",
    "sbs = SBS(et, k_features=5)\n",
    "sbs.fit(X_train_std, Y_train)\n",
    "\n",
    "# plotting performance of feature subsets\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.0])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./sbs.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k5 = list(sbs.subsets_[10])\n",
    "print(X.columns[1:][k5])\n",
    "#print(k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.fit(X_train_std, Y_train)\n",
    "print('Training accuracy:', et.score(X_train_std, Y_train))\n",
    "print('Test accuracy:', et.score(X_test_std, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et.fit(X_train_std[:, k5], Y_train)\n",
    "print('Training accuracy:', et.score(X_train_std[:, k5], Y_train))\n",
    "print('Test accuracy:', et.score(X_test_std[:, k5], Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
