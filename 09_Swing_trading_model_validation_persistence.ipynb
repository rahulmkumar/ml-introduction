{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_class(row):\n",
    "    if row < 0.00:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_return_class(row, neg_cutoff, pos_cutoff):\n",
    "    if row <= neg_cutoff:\n",
    "        return 0\n",
    "    elif row > neg_cutoff and row < pos_cutoff:\n",
    "        return 1\n",
    "    elif row >= pos_cutoff:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/price_data_68.csv')\n",
    "data1 = pd.read_csv('data/price_data_1.csv')\n",
    "data2 = pd.read_csv('data/price_data_2.csv')\n",
    "data3 = pd.read_csv('data/price_data_3.csv')\n",
    "data4 = pd.read_csv('data/price_data_4.csv')\n",
    "data5 = pd.read_csv('data/price_data_5.csv')\n",
    "data6 = pd.read_csv('data/price_data_6.csv')\n",
    "data7 = pd.read_csv('data/price_data_7.csv')\n",
    "data8 = pd.read_csv('data/price_data_8.csv')\n",
    "\n",
    "del data['Date']\n",
    "del data1['Date']\n",
    "del data2['Date']\n",
    "del data3['Date']\n",
    "del data4['Date']\n",
    "del data5['Date']\n",
    "del data6['Date']\n",
    "del data7['Date']\n",
    "del data8['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process only the main training data\n",
    "X = data.loc[:,'F1':'F68']\n",
    "y5 = data.loc[:,'RET5']\n",
    "y10 = data.loc[:,'RET10']\n",
    "y15 = data.loc[:,'RET15']\n",
    "y20 = data.loc[:,'RET20']\n",
    "y25 = data.loc[:,'RET25']\n",
    "y30 = data.loc[:,'RET30']\n",
    "\n",
    "y5.columns = ['RET']\n",
    "y10.columns = ['RET']\n",
    "y15.columns = ['RET']\n",
    "y20.columns = ['RET']\n",
    "y25.columns = ['RET']\n",
    "y30.columns = ['RET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y5_b = pd.Series(index=y5.index)\n",
    "y10_b = pd.Series(index=y5.index)\n",
    "y15_b = pd.Series(index=y5.index)\n",
    "y20_b = pd.Series(index=y5.index)\n",
    "y25_b = pd.Series(index=y5.index)\n",
    "y30_b = pd.Series(index=y5.index)\n",
    "\n",
    "y5_b = y5.apply(binary_class)\n",
    "y10_b = y10.apply(binary_class)\n",
    "y15_b = y15.apply(binary_class)\n",
    "y20_b = y20.apply(binary_class)\n",
    "y25_b = y25.apply(binary_class)\n",
    "y30_b = y30.apply(binary_class)\n",
    "\n",
    "\n",
    "y5_t = pd.Series(index=y5.index)\n",
    "y10_t = pd.Series(index=y5.index)\n",
    "y15_t = pd.Series(index=y5.index)\n",
    "y20_t = pd.Series(index=y5.index)\n",
    "y25_t = pd.Series(index=y5.index)\n",
    "y30_t = pd.Series(index=y5.index)\n",
    "\n",
    "y5_t = y5.apply(update_return_class, args=(-0.02, 0.02))\n",
    "y10_t = y10.apply(update_return_class, args=(-0.03, 0.03))\n",
    "y15_t = y15.apply(update_return_class, args=(-0.05, 0.05))\n",
    "y20_t = y20.apply(update_return_class, args=(-0.05, 0.05))\n",
    "y25_t = y25.apply(update_return_class, args=(-0.05, 0.07))\n",
    "y30_t = y30.apply(update_return_class, args=(-0.05, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.loc[:,['F19','F35','F36','F37','F38','F39','F40','F41','F46','F47','F52','F54','F55','F56','F57','F58','F59','F64','F66','F67']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=250, max_depth=25)\n",
    "stdsc = StandardScaler()\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5b_train, X5b_test, y5b_train, y5b_test = cross_validation.train_test_split(X, y5_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X10b_train, X10b_test, y10b_train, y10b_test = cross_validation.train_test_split(X, y10_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X15b_train, X15b_test, y15b_train, y15b_test = cross_validation.train_test_split(X, y15_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X20b_train, X20b_test, y20b_train, y20b_test = cross_validation.train_test_split(X, y20_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X25b_train, X25b_test, y25b_train, y25b_test = cross_validation.train_test_split(X, y25_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X30b_train, X30b_test, y30b_train, y30b_test = cross_validation.train_test_split(X, y30_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "\n",
    "X5t_train, X5t_test, y5t_train, y5t_test = cross_validation.train_test_split(X, y5_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X10t_train, X10t_test, y10t_train, y10t_test = cross_validation.train_test_split(X, y10_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X15t_train, X15t_test, y15t_train, y15t_test = cross_validation.train_test_split(X, y15_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X20t_train, X20t_test, y20t_train, y20t_test = cross_validation.train_test_split(X, y20_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X25t_train, X25t_test, y25t_train, y25t_test = cross_validation.train_test_split(X, y25_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X30t_train, X30t_test, y30t_train, y30t_test = cross_validation.train_test_split(X, y30_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_model(X_train, X_test, y_train, y_test, scale_model, predict_model):\n",
    "    X_train_std = scale_model.transform(X_train)\n",
    "    X_test_std = scale_model.transform(X_test)\n",
    "\n",
    "    predict_model.fit(X_train_std, y_train)\n",
    "    predict = predict_model.predict(X_test_std)\n",
    "\n",
    "    print(accuracy_score(y_test, predict))\n",
    "    print(confusion_matrix(y_test, predict))\n",
    "    print(classification_report(y_test, predict))\n",
    "    \n",
    "    return predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_saved_model(X, y, scale_model, predict_model):\n",
    "    X_std = scale_model.transform(X)\n",
    "\n",
    "    predict = predict_model.predict(X_std)\n",
    "\n",
    "    print(accuracy_score(y, predict))\n",
    "    print(confusion_matrix(y, predict))\n",
    "    print(classification_report(y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "Prediction for: 10-day Binary \n",
      "0.864064602961\n",
      "[[276  59]\n",
      " [ 42 366]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.82      0.85       335\n",
      "          1       0.86      0.90      0.88       408\n",
      "\n",
      "avg / total       0.86      0.86      0.86       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 5-day Trinary \n",
      "0.807537012113\n",
      "[[270  68]\n",
      " [ 75 330]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.80      0.79       338\n",
      "          1       0.83      0.81      0.82       405\n",
      "\n",
      "avg / total       0.81      0.81      0.81       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 25-day Trinary \n",
      "0.876177658143\n",
      "[[199  25   1]\n",
      " [ 21 180  27]\n",
      " [  0  18 272]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.88      0.89       225\n",
      "          1       0.81      0.79      0.80       228\n",
      "          2       0.91      0.94      0.92       290\n",
      "\n",
      "avg / total       0.88      0.88      0.88       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 10-day Trinary \n",
      "0.781965006729\n",
      "[[179  39   4]\n",
      " [ 31 153  48]\n",
      " [  1  39 249]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.81      0.83       222\n",
      "          1       0.66      0.66      0.66       232\n",
      "          2       0.83      0.86      0.84       289\n",
      "\n",
      "avg / total       0.78      0.78      0.78       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 15-day Binary \n",
      "0.877523553163\n",
      "[[272  51]\n",
      " [ 40 380]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.84      0.86       323\n",
      "          1       0.88      0.90      0.89       420\n",
      "\n",
      "avg / total       0.88      0.88      0.88       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 15-day Trinary \n",
      "0.829071332436\n",
      "[[166  24   1]\n",
      " [ 26 227  37]\n",
      " [  1  38 223]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.87      0.86       191\n",
      "          1       0.79      0.78      0.78       290\n",
      "          2       0.85      0.85      0.85       262\n",
      "\n",
      "avg / total       0.83      0.83      0.83       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 30-day Binary \n",
      "0.935397039031\n",
      "[[282  30]\n",
      " [ 18 413]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92       312\n",
      "          1       0.93      0.96      0.95       431\n",
      "\n",
      "avg / total       0.94      0.94      0.94       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 5-day Binary \n",
      "0.814266487214\n",
      "[[270  68]\n",
      " [ 70 335]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.80      0.80       338\n",
      "          1       0.83      0.83      0.83       405\n",
      "\n",
      "avg / total       0.81      0.81      0.81       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 30-day Trinary \n",
      "0.893674293405\n",
      "[[203  22   0]\n",
      " [ 22 187  21]\n",
      " [  0  14 274]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90       225\n",
      "          1       0.84      0.81      0.83       230\n",
      "          2       0.93      0.95      0.94       288\n",
      "\n",
      "avg / total       0.89      0.89      0.89       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 25-day Binary \n",
      "0.93135935397\n",
      "[[289  34]\n",
      " [ 17 403]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.92       323\n",
      "          1       0.92      0.96      0.94       420\n",
      "\n",
      "avg / total       0.93      0.93      0.93       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 20-day Binary \n",
      "0.916554508748\n",
      "[[289  38]\n",
      " [ 24 392]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.88      0.90       327\n",
      "          1       0.91      0.94      0.93       416\n",
      "\n",
      "avg / total       0.92      0.92      0.92       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 20-day Trinary \n",
      "0.845222072678\n",
      "[[185  26   0]\n",
      " [ 28 172  31]\n",
      " [  0  30 271]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.87       211\n",
      "          1       0.75      0.74      0.75       231\n",
      "          2       0.90      0.90      0.90       301\n",
      "\n",
      "avg / total       0.84      0.85      0.84       743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scale data only once and re-use the scaling transformer for other models\n",
    "_ = stdsc.fit_transform(X5b_train)\n",
    "\n",
    "data_split = {\n",
    "    '5b':{\n",
    "        'descr':'5-day Binary',\n",
    "        'X_train':X5b_train,\n",
    "        'X_test':X5b_test,\n",
    "        'y_train':y5b_train,\n",
    "        'y_test':y5b_test\n",
    "    },\n",
    "    '10b':{\n",
    "        'descr':'10-day Binary',\n",
    "        'X_train':X10b_train,\n",
    "        'X_test':X10b_test,\n",
    "        'y_train':y10b_train,\n",
    "        'y_test':y10b_test\n",
    "    },\n",
    "    '15b':{\n",
    "        'descr':'15-day Binary',\n",
    "        'X_train':X15b_train,\n",
    "        'X_test':X15b_test,\n",
    "        'y_train':y15b_train,\n",
    "        'y_test':y15b_test\n",
    "    },\n",
    "    '20b':{\n",
    "        'descr':'20-day Binary',\n",
    "        'X_train':X20b_train,\n",
    "        'X_test':X20b_test,\n",
    "        'y_train':y20b_train,\n",
    "        'y_test':y20b_test\n",
    "    },\n",
    "    '25b':{\n",
    "        'descr':'25-day Binary',\n",
    "        'X_train':X25b_train,\n",
    "        'X_test':X25b_test,\n",
    "        'y_train':y25b_train,\n",
    "        'y_test':y25b_test\n",
    "    },\n",
    "    '30b':{\n",
    "        'descr':'30-day Binary',\n",
    "        'X_train':X30b_train,\n",
    "        'X_test':X30b_test,\n",
    "        'y_train':y30b_train,\n",
    "        'y_test':y30b_test\n",
    "    },\n",
    "    '5t':{\n",
    "        'descr':'5-day Trinary',\n",
    "        'X_train':X5b_train,\n",
    "        'X_test':X5b_test,\n",
    "        'y_train':y5b_train,\n",
    "        'y_test':y5b_test\n",
    "    },\n",
    "    '10t':{\n",
    "        'descr':'10-day Trinary',\n",
    "        'X_train':X10t_train,\n",
    "        'X_test':X10t_test,\n",
    "        'y_train':y10t_train,\n",
    "        'y_test':y10t_test\n",
    "    },\n",
    "    '15t':{\n",
    "        'descr':'15-day Trinary',\n",
    "        'X_train':X15t_train,\n",
    "        'X_test':X15t_test,\n",
    "        'y_train':y15t_train,\n",
    "        'y_test':y15t_test\n",
    "    },\n",
    "    '20t':{\n",
    "        'descr':'20-day Trinary',\n",
    "        'X_train':X20t_train,\n",
    "        'X_test':X20t_test,\n",
    "        'y_train':y20t_train,\n",
    "        'y_test':y20t_test\n",
    "    },\n",
    "    '25t':{\n",
    "        'descr':'25-day Trinary',\n",
    "        'X_train':X25t_train,\n",
    "        'X_test':X25t_test,\n",
    "        'y_train':y25t_train,\n",
    "        'y_test':y25t_test\n",
    "    },\n",
    "    '30t':{\n",
    "        'descr':'30-day Trinary',\n",
    "        'X_train':X30t_train,\n",
    "        'X_test':X30t_test,\n",
    "        'y_train':y30t_train,\n",
    "        'y_test':y30t_test\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {}\n",
    "\n",
    "for key in data_split:\n",
    "    print('-------------------------------------------------------------')\n",
    "    print('Prediction for: %s ' % data_split[str(key)]['descr'])\n",
    "    predict = prediction_model(data_split[key]['X_train'], data_split[key]['X_test'], \n",
    "                                data_split[key]['y_train'], data_split[key]['y_test'], \n",
    "                                stdsc, et)\n",
    "    models[key] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/predict.mod']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaling_model_file = 'models/scale.mod'\n",
    "joblib.dump(stdsc,scaling_model_file, compress=1)\n",
    "\n",
    "predict_model_file = 'models/predict.mod'\n",
    "joblib.dump(models,predict_model_file, compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for: 10b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 5t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 25t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 10t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 15b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 15t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 30b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 5b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 30t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 25b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 20b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 20t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "prediction_models = joblib.load(predict_model_file)\n",
    "\n",
    "for key in prediction_models:\n",
    "    print('Model for: %s' % key)\n",
    "    print(prediction_models[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
