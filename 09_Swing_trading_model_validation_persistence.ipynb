{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_class(row):\n",
    "    if row < 0.00:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_return_class(row, neg_cutoff, pos_cutoff):\n",
    "    if row <= neg_cutoff:\n",
    "        return 0\n",
    "    elif row > neg_cutoff and row < pos_cutoff:\n",
    "        return 1\n",
    "    elif row >= pos_cutoff:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/price_data_68.csv')\n",
    "del data['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process only the main training data\n",
    "X = data.loc[:,'F1':'F68']\n",
    "y5 = data.loc[:,'RET5']\n",
    "y10 = data.loc[:,'RET10']\n",
    "y15 = data.loc[:,'RET15']\n",
    "y20 = data.loc[:,'RET20']\n",
    "y25 = data.loc[:,'RET25']\n",
    "y30 = data.loc[:,'RET30']\n",
    "\n",
    "y5.columns = ['RET']\n",
    "y10.columns = ['RET']\n",
    "y15.columns = ['RET']\n",
    "y20.columns = ['RET']\n",
    "y25.columns = ['RET']\n",
    "y30.columns = ['RET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y5_b = pd.Series(index=y5.index)\n",
    "y10_b = pd.Series(index=y5.index)\n",
    "y15_b = pd.Series(index=y5.index)\n",
    "y20_b = pd.Series(index=y5.index)\n",
    "y25_b = pd.Series(index=y5.index)\n",
    "y30_b = pd.Series(index=y5.index)\n",
    "\n",
    "y5_b = y5.apply(binary_class)\n",
    "y10_b = y10.apply(binary_class)\n",
    "y15_b = y15.apply(binary_class)\n",
    "y20_b = y20.apply(binary_class)\n",
    "y25_b = y25.apply(binary_class)\n",
    "y30_b = y30.apply(binary_class)\n",
    "\n",
    "\n",
    "y5_t = pd.Series(index=y5.index)\n",
    "y10_t = pd.Series(index=y5.index)\n",
    "y15_t = pd.Series(index=y5.index)\n",
    "y20_t = pd.Series(index=y5.index)\n",
    "y25_t = pd.Series(index=y5.index)\n",
    "y30_t = pd.Series(index=y5.index)\n",
    "\n",
    "y5_t = y5.apply(update_return_class, args=(-0.02, 0.02))\n",
    "y10_t = y10.apply(update_return_class, args=(-0.03, 0.03))\n",
    "y15_t = y15.apply(update_return_class, args=(-0.05, 0.05))\n",
    "y20_t = y20.apply(update_return_class, args=(-0.05, 0.05))\n",
    "y25_t = y25.apply(update_return_class, args=(-0.05, 0.07))\n",
    "y30_t = y30.apply(update_return_class, args=(-0.05, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.loc[:,['F19','F35','F36','F37','F38','F39','F40','F41','F46','F47','F52','F54','F55','F56','F57','F58','F59','F64','F66','F67']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=250, max_depth=25)\n",
    "stdsc = StandardScaler()\n",
    "scale = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5b_train, X5b_test, y5b_train, y5b_test = cross_validation.train_test_split(X, y5_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X10b_train, X10b_test, y10b_train, y10b_test = cross_validation.train_test_split(X, y10_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X15b_train, X15b_test, y15b_train, y15b_test = cross_validation.train_test_split(X, y15_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X20b_train, X20b_test, y20b_train, y20b_test = cross_validation.train_test_split(X, y20_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X25b_train, X25b_test, y25b_train, y25b_test = cross_validation.train_test_split(X, y25_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X30b_train, X30b_test, y30b_train, y30b_test = cross_validation.train_test_split(X, y30_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "\n",
    "X5t_train, X5t_test, y5t_train, y5t_test = cross_validation.train_test_split(X, y5_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X10t_train, X10t_test, y10t_train, y10t_test = cross_validation.train_test_split(X, y10_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X15t_train, X15t_test, y15t_train, y15t_test = cross_validation.train_test_split(X, y15_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X20t_train, X20t_test, y20t_train, y20t_test = cross_validation.train_test_split(X, y20_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X25t_train, X25t_test, y25t_train, y25t_test = cross_validation.train_test_split(X, y25_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X30t_train, X30t_test, y30t_train, y30t_test = cross_validation.train_test_split(X, y30_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_model(X_train, X_test, y_train, y_test, scale_model, predict_model):\n",
    "    X_train_std = scale_model.transform(X_train)\n",
    "    X_test_std = scale_model.transform(X_test)\n",
    "\n",
    "    predict_model.fit(X_train_std, y_train)\n",
    "    predict = predict_model.predict(X_test_std)\n",
    "\n",
    "    print(accuracy_score(y_test, predict))\n",
    "    print(confusion_matrix(y_test, predict))\n",
    "    print(classification_report(y_test, predict))\n",
    "    \n",
    "    return predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_saved_model(X, y, scale_model, predict_model):\n",
    "    #X_std = scale_model.transform(X)\n",
    "    scale = MinMaxScaler()\n",
    "    X_std = scale.fit_transform(X)\n",
    "\n",
    "    predict = predict_model.predict(X_std)\n",
    "\n",
    "    print(accuracy_score(y, predict))\n",
    "    print(confusion_matrix(y, predict))\n",
    "    print(classification_report(y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale data only once and re-use the scaling transformer for other models\n",
    "_ = stdsc.fit_transform(X5b_train)\n",
    "_ = scale.fit_transform(X5b_train)\n",
    "\n",
    "data_split = {\n",
    "    '5b':{\n",
    "        'descr':'5-day Binary',\n",
    "        'X_train':X5b_train,\n",
    "        'X_test':X5b_test,\n",
    "        'y_train':y5b_train,\n",
    "        'y_test':y5b_test\n",
    "    },\n",
    "    '10b':{\n",
    "        'descr':'10-day Binary',\n",
    "        'X_train':X10b_train,\n",
    "        'X_test':X10b_test,\n",
    "        'y_train':y10b_train,\n",
    "        'y_test':y10b_test\n",
    "    },\n",
    "    '15b':{\n",
    "        'descr':'15-day Binary',\n",
    "        'X_train':X15b_train,\n",
    "        'X_test':X15b_test,\n",
    "        'y_train':y15b_train,\n",
    "        'y_test':y15b_test\n",
    "    },\n",
    "    '20b':{\n",
    "        'descr':'20-day Binary',\n",
    "        'X_train':X20b_train,\n",
    "        'X_test':X20b_test,\n",
    "        'y_train':y20b_train,\n",
    "        'y_test':y20b_test\n",
    "    },\n",
    "    '25b':{\n",
    "        'descr':'25-day Binary',\n",
    "        'X_train':X25b_train,\n",
    "        'X_test':X25b_test,\n",
    "        'y_train':y25b_train,\n",
    "        'y_test':y25b_test\n",
    "    },\n",
    "    '30b':{\n",
    "        'descr':'30-day Binary',\n",
    "        'X_train':X30b_train,\n",
    "        'X_test':X30b_test,\n",
    "        'y_train':y30b_train,\n",
    "        'y_test':y30b_test\n",
    "    },\n",
    "    '5t':{\n",
    "        'descr':'5-day Trinary',\n",
    "        'X_train':X5b_train,\n",
    "        'X_test':X5b_test,\n",
    "        'y_train':y5b_train,\n",
    "        'y_test':y5b_test\n",
    "    },\n",
    "    '10t':{\n",
    "        'descr':'10-day Trinary',\n",
    "        'X_train':X10t_train,\n",
    "        'X_test':X10t_test,\n",
    "        'y_train':y10t_train,\n",
    "        'y_test':y10t_test\n",
    "    },\n",
    "    '15t':{\n",
    "        'descr':'15-day Trinary',\n",
    "        'X_train':X15t_train,\n",
    "        'X_test':X15t_test,\n",
    "        'y_train':y15t_train,\n",
    "        'y_test':y15t_test\n",
    "    },\n",
    "    '20t':{\n",
    "        'descr':'20-day Trinary',\n",
    "        'X_train':X20t_train,\n",
    "        'X_test':X20t_test,\n",
    "        'y_train':y20t_train,\n",
    "        'y_test':y20t_test\n",
    "    },\n",
    "    '25t':{\n",
    "        'descr':'25-day Trinary',\n",
    "        'X_train':X25t_train,\n",
    "        'X_test':X25t_test,\n",
    "        'y_train':y25t_train,\n",
    "        'y_test':y25t_test\n",
    "    },\n",
    "    '30t':{\n",
    "        'descr':'30-day Trinary',\n",
    "        'X_train':X30t_train,\n",
    "        'X_test':X30t_test,\n",
    "        'y_train':y30t_train,\n",
    "        'y_test':y30t_test\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {}\n",
    "\n",
    "for key in data_split:\n",
    "    print('-------------------------------------------------------------')\n",
    "    print('Prediction for: %s ' % data_split[str(key)]['descr'])\n",
    "    predict = prediction_model(data_split[key]['X_train'], data_split[key]['X_test'], \n",
    "                                data_split[key]['y_train'], data_split[key]['y_test'], \n",
    "                                scale, et)\n",
    "    predict_model_file = 'models/'+key+'.mod'\n",
    "    joblib.dump(predict,predict_model_file, compress=1)\n",
    "    models[key] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/predict.mod']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaling_model_file = 'models/scale.mod'\n",
    "joblib.dump(stdsc,scaling_model_file, compress=1)\n",
    "\n",
    "predict_model_file = 'models/predict.mod'\n",
    "joblib.dump(models,predict_model_file, compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_models = joblib.load(predict_model_file)\n",
    "\n",
    "for key in prediction_models:\n",
    "    print('Model for: %s' % key)\n",
    "    print(prediction_models[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3713"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = {'file1':'data/price_data_1.csv',\n",
    "             'file2':'data/price_data_2.csv',\n",
    "             'file3':'data/price_data_3.csv',\n",
    "             'file4':'data/price_data_4.csv',\n",
    "             'file5':'data/price_data_5.csv',\n",
    "             'file6':'data/price_data_6.csv',\n",
    "             'file7':'data/price_data_7.csv',\n",
    "             'file8':'data/price_data_8.csv'}\n",
    "\n",
    "test_file = {'file1':'data/price_data_1.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaling_model_file = 'models/scale.mod'\n",
    "predict_model_file = 'models/predict.mod'\n",
    "predict_model_files = {'5b':'models/5b.mod',\n",
    "                      '10b':'models/10b.mod',\n",
    "                      '15b':'models/15b.mod',\n",
    "                      '20b':'models/20b.mod',\n",
    "                      '25b':'models/25b.mod',\n",
    "                      '30b':'models/30b.mod',\n",
    "                      '5t':'models/5t.mod',\n",
    "                      '10t':'models/10t.mod',\n",
    "                      '15t':'models/15t.mod',\n",
    "                      '20t':'models/20t.mod',\n",
    "                      '25t':'models/25t.mod',\n",
    "                      '30t':'models/30t.mod'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features_labels(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    del data['Date']\n",
    "    #X = data.loc[:,'F1':'F68']\n",
    "    X = data.loc[:,['F19','F35','F36','F37','F38','F39','F40','F41','F46','F47','F52','F54','F55','F56','F57',\n",
    "                    'F58','F59','F64','F66','F67']]\n",
    "    y5 = data.loc[:,'RET5']\n",
    "    y10 = data.loc[:,'RET10']\n",
    "    y15 = data.loc[:,'RET15']\n",
    "    y20 = data.loc[:,'RET20']\n",
    "    y25 = data.loc[:,'RET25']\n",
    "    y30 = data.loc[:,'RET30']\n",
    "\n",
    "    y5.columns = ['RET']\n",
    "    y10.columns = ['RET']\n",
    "    y15.columns = ['RET']\n",
    "    y20.columns = ['RET']\n",
    "    y25.columns = ['RET']\n",
    "    y30.columns = ['RET']\n",
    "    \n",
    "    y5_b = pd.Series(index=y5.index)\n",
    "    y10_b = pd.Series(index=y5.index)\n",
    "    y15_b = pd.Series(index=y5.index)\n",
    "    y20_b = pd.Series(index=y5.index)\n",
    "    y25_b = pd.Series(index=y5.index)\n",
    "    y30_b = pd.Series(index=y5.index)\n",
    "\n",
    "    y5_b = y5.apply(binary_class)\n",
    "    y10_b = y10.apply(binary_class)\n",
    "    y15_b = y15.apply(binary_class)\n",
    "    y20_b = y20.apply(binary_class)\n",
    "    y25_b = y25.apply(binary_class)\n",
    "    y30_b = y30.apply(binary_class)\n",
    "\n",
    "\n",
    "    y5_t = pd.Series(index=y5.index)\n",
    "    y10_t = pd.Series(index=y5.index)\n",
    "    y15_t = pd.Series(index=y5.index)\n",
    "    y20_t = pd.Series(index=y5.index)\n",
    "    y25_t = pd.Series(index=y5.index)\n",
    "    y30_t = pd.Series(index=y5.index)\n",
    "\n",
    "    y5_t = y5.apply(update_return_class, args=(-0.02, 0.02))\n",
    "    y10_t = y10.apply(update_return_class, args=(-0.03, 0.03))\n",
    "    y15_t = y15.apply(update_return_class, args=(-0.05, 0.05))\n",
    "    y20_t = y20.apply(update_return_class, args=(-0.05, 0.05))\n",
    "    y25_t = y25.apply(update_return_class, args=(-0.05, 0.07))\n",
    "    y30_t = y30.apply(update_return_class, args=(-0.05, 0.08))\n",
    "    \n",
    "    labels = {'binary':{'5b':y5_b,\n",
    "                        '10b':y10_b,\n",
    "                        '15b':y15_b,\n",
    "                        '20b':y20_b,\n",
    "                        '25b':y25_b,\n",
    "                        '30b':y30_b},\n",
    "             'trinary':{'5t':y5_t,\n",
    "                        '10t':y10_t,\n",
    "                        '15t':y15_t,\n",
    "                        '20t':y20_t,\n",
    "                        '25t':y25_t,\n",
    "                        '30t':y30_t}}\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_validation(file_names, scale_model_file, predict_model_file):\n",
    "    scaling_model = joblib.load(scale_model_file)\n",
    "    #prediction_models = joblib.load(predict_model_file)\n",
    "\n",
    "    for file in file_names:\n",
    "        X, labels = get_features_labels(file_names[file])        \n",
    "        for label_type in labels:\n",
    "            for model in labels[label_type]:\n",
    "                print('-------------------------------------------')\n",
    "                print('File:FileNames - %s:%s' %(file,file_names[file]))\n",
    "                print('Label Type: %s' %label_type)\n",
    "                print('Model: %s' %model)\n",
    "                prediction_models = joblib.load(predict_model_files[model])\n",
    "                print('Prediction Model File: %s' %predict_model_files[model])\n",
    "                label_data = labels[label_type][model]\n",
    "                #prediction_saved_model(X, label_data, scaling_model, prediction_models[model])\n",
    "                prediction_saved_model(X, label_data, scaling_model, prediction_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model_validation(test_file, scaling_model_file, predict_model_file)\n",
    "model_validation(test_file, scaling_model_file, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/test.mod']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = {'file1':'data/price_data_68.csv'}\n",
    "X, labels = get_features_labels('data/price_data_68.csv')\n",
    "X_scaled = scale.fit_transform(X)\n",
    "et.fit(X_scaled, labels['binary']['20b'])\n",
    "joblib.dump(et, 'models/test.mod', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496906107076\n",
      "[[1060  618]\n",
      " [1252  787]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.63      0.53      1678\n",
      "          1       0.56      0.39      0.46      2039\n",
      "\n",
      "avg / total       0.51      0.50      0.49      3717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('models/test.mod')\n",
    "\n",
    "scale1 = MinMaxScaler()\n",
    "\n",
    "file = 'data/price_data_8.csv'\n",
    "X, labels = get_features_labels(file)\n",
    "X_scaled = scale1.fit_transform(X)\n",
    "\n",
    "predict = model.predict(X_scaled)\n",
    "\n",
    "print(accuracy_score(labels['binary']['20b'], predict))\n",
    "print(confusion_matrix(labels['binary']['20b'], predict))\n",
    "print(classification_report(labels['binary']['20b'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
