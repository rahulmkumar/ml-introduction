{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_class(row):\n",
    "    if row < 0.00:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_return_class(row, neg_cutoff, pos_cutoff):\n",
    "    if row <= neg_cutoff:\n",
    "        return 0\n",
    "    elif row > neg_cutoff and row < pos_cutoff:\n",
    "        return 1\n",
    "    elif row >= pos_cutoff:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/price_data_68.csv')\n",
    "del data['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process only the main training data\n",
    "X = data.loc[:,'F1':'F68']\n",
    "y5 = data.loc[:,'RET5']\n",
    "y10 = data.loc[:,'RET10']\n",
    "y15 = data.loc[:,'RET15']\n",
    "y20 = data.loc[:,'RET20']\n",
    "y25 = data.loc[:,'RET25']\n",
    "y30 = data.loc[:,'RET30']\n",
    "\n",
    "y5.columns = ['RET']\n",
    "y10.columns = ['RET']\n",
    "y15.columns = ['RET']\n",
    "y20.columns = ['RET']\n",
    "y25.columns = ['RET']\n",
    "y30.columns = ['RET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y5_b = pd.Series(index=y5.index)\n",
    "y10_b = pd.Series(index=y5.index)\n",
    "y15_b = pd.Series(index=y5.index)\n",
    "y20_b = pd.Series(index=y5.index)\n",
    "y25_b = pd.Series(index=y5.index)\n",
    "y30_b = pd.Series(index=y5.index)\n",
    "\n",
    "y5_b = y5.apply(binary_class)\n",
    "y10_b = y10.apply(binary_class)\n",
    "y15_b = y15.apply(binary_class)\n",
    "y20_b = y20.apply(binary_class)\n",
    "y25_b = y25.apply(binary_class)\n",
    "y30_b = y30.apply(binary_class)\n",
    "\n",
    "\n",
    "y5_t = pd.Series(index=y5.index)\n",
    "y10_t = pd.Series(index=y5.index)\n",
    "y15_t = pd.Series(index=y5.index)\n",
    "y20_t = pd.Series(index=y5.index)\n",
    "y25_t = pd.Series(index=y5.index)\n",
    "y30_t = pd.Series(index=y5.index)\n",
    "\n",
    "y5_t = y5.apply(update_return_class, args=(-0.02, 0.02))\n",
    "y10_t = y10.apply(update_return_class, args=(-0.03, 0.03))\n",
    "y15_t = y15.apply(update_return_class, args=(-0.05, 0.05))\n",
    "y20_t = y20.apply(update_return_class, args=(-0.05, 0.05))\n",
    "y25_t = y25.apply(update_return_class, args=(-0.05, 0.07))\n",
    "y30_t = y30.apply(update_return_class, args=(-0.05, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.loc[:,['F19','F35','F36','F37','F38','F39','F40','F41','F46','F47','F52','F54','F55','F56','F57','F58','F59','F64','F66','F67']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=250, max_depth=25)\n",
    "stdsc = StandardScaler()\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5b_train, X5b_test, y5b_train, y5b_test = cross_validation.train_test_split(X, y5_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X10b_train, X10b_test, y10b_train, y10b_test = cross_validation.train_test_split(X, y10_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X15b_train, X15b_test, y15b_train, y15b_test = cross_validation.train_test_split(X, y15_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X20b_train, X20b_test, y20b_train, y20b_test = cross_validation.train_test_split(X, y20_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X25b_train, X25b_test, y25b_train, y25b_test = cross_validation.train_test_split(X, y25_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X30b_train, X30b_test, y30b_train, y30b_test = cross_validation.train_test_split(X, y30_b, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "\n",
    "X5t_train, X5t_test, y5t_train, y5t_test = cross_validation.train_test_split(X, y5_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X10t_train, X10t_test, y10t_train, y10t_test = cross_validation.train_test_split(X, y10_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X15t_train, X15t_test, y15t_train, y15t_test = cross_validation.train_test_split(X, y15_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X20t_train, X20t_test, y20t_train, y20t_test = cross_validation.train_test_split(X, y20_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X25t_train, X25t_test, y25t_train, y25t_test = cross_validation.train_test_split(X, y25_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)\n",
    "X30t_train, X30t_test, y30t_train, y30t_test = cross_validation.train_test_split(X, y30_t, test_size=validation_size, \n",
    "                                                                                 random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_model(X_train, X_test, y_train, y_test, scale_model, predict_model):\n",
    "    X_train_std = scale_model.transform(X_train)\n",
    "    X_test_std = scale_model.transform(X_test)\n",
    "\n",
    "    predict_model.fit(X_train_std, y_train)\n",
    "    predict = predict_model.predict(X_test_std)\n",
    "\n",
    "    print(accuracy_score(y_test, predict))\n",
    "    print(confusion_matrix(y_test, predict))\n",
    "    print(classification_report(y_test, predict))\n",
    "    \n",
    "    return predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_saved_model(X, y, scale_model, predict_model):\n",
    "    X_std = scale_model.transform(X)\n",
    "\n",
    "    predict = predict_model.predict(X_std)\n",
    "\n",
    "    print(accuracy_score(y, predict))\n",
    "    print(confusion_matrix(y, predict))\n",
    "    print(classification_report(y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "Prediction for: 5-day Binary \n",
      "0.816958277254\n",
      "[[273  65]\n",
      " [ 71 334]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.81      0.80       338\n",
      "          1       0.84      0.82      0.83       405\n",
      "\n",
      "avg / total       0.82      0.82      0.82       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 20-day Trinary \n",
      "0.843876177658\n",
      "[[185  26   0]\n",
      " [ 30 171  30]\n",
      " [  0  30 271]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.88      0.87       211\n",
      "          1       0.75      0.74      0.75       231\n",
      "          2       0.90      0.90      0.90       301\n",
      "\n",
      "avg / total       0.84      0.84      0.84       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 30-day Binary \n",
      "0.935397039031\n",
      "[[281  31]\n",
      " [ 17 414]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92       312\n",
      "          1       0.93      0.96      0.95       431\n",
      "\n",
      "avg / total       0.94      0.94      0.94       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 20-day Binary \n",
      "0.915208613728\n",
      "[[287  40]\n",
      " [ 23 393]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.88      0.90       327\n",
      "          1       0.91      0.94      0.93       416\n",
      "\n",
      "avg / total       0.92      0.92      0.91       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 30-day Trinary \n",
      "0.892328398385\n",
      "[[202  23   0]\n",
      " [ 23 188  19]\n",
      " [  0  15 273]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90       225\n",
      "          1       0.83      0.82      0.82       230\n",
      "          2       0.93      0.95      0.94       288\n",
      "\n",
      "avg / total       0.89      0.89      0.89       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 15-day Binary \n",
      "0.878869448183\n",
      "[[273  50]\n",
      " [ 40 380]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.85      0.86       323\n",
      "          1       0.88      0.90      0.89       420\n",
      "\n",
      "avg / total       0.88      0.88      0.88       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 25-day Binary \n",
      "0.93135935397\n",
      "[[289  34]\n",
      " [ 17 403]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.92       323\n",
      "          1       0.92      0.96      0.94       420\n",
      "\n",
      "avg / total       0.93      0.93      0.93       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 10-day Binary \n",
      "0.874831763122\n",
      "[[279  56]\n",
      " [ 37 371]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.86       335\n",
      "          1       0.87      0.91      0.89       408\n",
      "\n",
      "avg / total       0.88      0.87      0.87       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 15-day Trinary \n",
      "0.831763122476\n",
      "[[165  25   1]\n",
      " [ 25 227  38]\n",
      " [  1  35 226]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.86      0.86       191\n",
      "          1       0.79      0.78      0.79       290\n",
      "          2       0.85      0.86      0.86       262\n",
      "\n",
      "avg / total       0.83      0.83      0.83       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 25-day Trinary \n",
      "0.880215343203\n",
      "[[200  24   1]\n",
      " [ 21 180  27]\n",
      " [  0  16 274]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.89      0.90       225\n",
      "          1       0.82      0.79      0.80       228\n",
      "          2       0.91      0.94      0.93       290\n",
      "\n",
      "avg / total       0.88      0.88      0.88       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 5-day Trinary \n",
      "0.807537012113\n",
      "[[274  64]\n",
      " [ 79 326]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.81      0.79       338\n",
      "          1       0.84      0.80      0.82       405\n",
      "\n",
      "avg / total       0.81      0.81      0.81       743\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Prediction for: 10-day Trinary \n",
      "0.78331090175\n",
      "[[179  37   6]\n",
      " [ 28 156  48]\n",
      " [  1  41 247]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.81      0.83       222\n",
      "          1       0.67      0.67      0.67       232\n",
      "          2       0.82      0.85      0.84       289\n",
      "\n",
      "avg / total       0.78      0.78      0.78       743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scale data only once and re-use the scaling transformer for other models\n",
    "_ = stdsc.fit_transform(X5b_train)\n",
    "\n",
    "data_split = {\n",
    "    '5b':{\n",
    "        'descr':'5-day Binary',\n",
    "        'X_train':X5b_train,\n",
    "        'X_test':X5b_test,\n",
    "        'y_train':y5b_train,\n",
    "        'y_test':y5b_test\n",
    "    },\n",
    "    '10b':{\n",
    "        'descr':'10-day Binary',\n",
    "        'X_train':X10b_train,\n",
    "        'X_test':X10b_test,\n",
    "        'y_train':y10b_train,\n",
    "        'y_test':y10b_test\n",
    "    },\n",
    "    '15b':{\n",
    "        'descr':'15-day Binary',\n",
    "        'X_train':X15b_train,\n",
    "        'X_test':X15b_test,\n",
    "        'y_train':y15b_train,\n",
    "        'y_test':y15b_test\n",
    "    },\n",
    "    '20b':{\n",
    "        'descr':'20-day Binary',\n",
    "        'X_train':X20b_train,\n",
    "        'X_test':X20b_test,\n",
    "        'y_train':y20b_train,\n",
    "        'y_test':y20b_test\n",
    "    },\n",
    "    '25b':{\n",
    "        'descr':'25-day Binary',\n",
    "        'X_train':X25b_train,\n",
    "        'X_test':X25b_test,\n",
    "        'y_train':y25b_train,\n",
    "        'y_test':y25b_test\n",
    "    },\n",
    "    '30b':{\n",
    "        'descr':'30-day Binary',\n",
    "        'X_train':X30b_train,\n",
    "        'X_test':X30b_test,\n",
    "        'y_train':y30b_train,\n",
    "        'y_test':y30b_test\n",
    "    },\n",
    "    '5t':{\n",
    "        'descr':'5-day Trinary',\n",
    "        'X_train':X5b_train,\n",
    "        'X_test':X5b_test,\n",
    "        'y_train':y5b_train,\n",
    "        'y_test':y5b_test\n",
    "    },\n",
    "    '10t':{\n",
    "        'descr':'10-day Trinary',\n",
    "        'X_train':X10t_train,\n",
    "        'X_test':X10t_test,\n",
    "        'y_train':y10t_train,\n",
    "        'y_test':y10t_test\n",
    "    },\n",
    "    '15t':{\n",
    "        'descr':'15-day Trinary',\n",
    "        'X_train':X15t_train,\n",
    "        'X_test':X15t_test,\n",
    "        'y_train':y15t_train,\n",
    "        'y_test':y15t_test\n",
    "    },\n",
    "    '20t':{\n",
    "        'descr':'20-day Trinary',\n",
    "        'X_train':X20t_train,\n",
    "        'X_test':X20t_test,\n",
    "        'y_train':y20t_train,\n",
    "        'y_test':y20t_test\n",
    "    },\n",
    "    '25t':{\n",
    "        'descr':'25-day Trinary',\n",
    "        'X_train':X25t_train,\n",
    "        'X_test':X25t_test,\n",
    "        'y_train':y25t_train,\n",
    "        'y_test':y25t_test\n",
    "    },\n",
    "    '30t':{\n",
    "        'descr':'30-day Trinary',\n",
    "        'X_train':X30t_train,\n",
    "        'X_test':X30t_test,\n",
    "        'y_train':y30t_train,\n",
    "        'y_test':y30t_test\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {}\n",
    "\n",
    "for key in data_split:\n",
    "    print('-------------------------------------------------------------')\n",
    "    print('Prediction for: %s ' % data_split[str(key)]['descr'])\n",
    "    predict = prediction_model(data_split[key]['X_train'], data_split[key]['X_test'], \n",
    "                                data_split[key]['y_train'], data_split[key]['y_test'], \n",
    "                                stdsc, et)\n",
    "    predict_model_file = 'models/'+key+'.mod'\n",
    "    joblib.dump(predict,predict_model_file, compress=1)\n",
    "    models[key] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/predict.mod']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaling_model_file = 'models/scale.mod'\n",
    "joblib.dump(stdsc,scaling_model_file, compress=1)\n",
    "\n",
    "predict_model_file = 'models/predict.mod'\n",
    "joblib.dump(models,predict_model_file, compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for: 5b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 20t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 30b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 20b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 30t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 15b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 25b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 10b\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 15t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 25t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 5t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Model for: 10t\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "prediction_models = joblib.load(predict_model_file)\n",
    "\n",
    "for key in prediction_models:\n",
    "    print('Model for: %s' % key)\n",
    "    print(prediction_models[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3713"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = {'file1':'data/price_data_1.csv',\n",
    "             'file2':'data/price_data_2.csv',\n",
    "             'file3':'data/price_data_3.csv',\n",
    "             'file4':'data/price_data_4.csv',\n",
    "             'file5':'data/price_data_5.csv',\n",
    "             'file6':'data/price_data_6.csv',\n",
    "             'file7':'data/price_data_7.csv',\n",
    "             'file8':'data/price_data_8.csv'}\n",
    "\n",
    "test_file = {'file1':'data/price_data_68.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaling_model_file = 'models/scale.mod'\n",
    "predict_model_file = 'models/predict.mod'\n",
    "predict_model_files = {'5b':'models/5b.mod',\n",
    "                      '10b':'models/10b.mod',\n",
    "                      '15b':'models/15b.mod',\n",
    "                      '20b':'models/20b.mod',\n",
    "                      '25b':'models/25b.mod',\n",
    "                      '30b':'models/30b.mod',\n",
    "                      '5t':'models/5t.mod',\n",
    "                      '10t':'models/10t.mod',\n",
    "                      '15t':'models/15t.mod',\n",
    "                      '20t':'models/20t.mod',\n",
    "                      '25t':'models/25t.mod',\n",
    "                      '30t':'models/30t.mod'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features_labels(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    del data['Date']\n",
    "    #X = data.loc[:,'F1':'F68']\n",
    "    X = data.loc[:,['F19','F35','F36','F37','F38','F39','F40','F41','F46','F47','F52','F54','F55','F56','F57',\n",
    "                    'F58','F59','F64','F66','F67']]\n",
    "    y5 = data.loc[:,'RET5']\n",
    "    y10 = data.loc[:,'RET10']\n",
    "    y15 = data.loc[:,'RET15']\n",
    "    y20 = data.loc[:,'RET20']\n",
    "    y25 = data.loc[:,'RET25']\n",
    "    y30 = data.loc[:,'RET30']\n",
    "\n",
    "    y5.columns = ['RET']\n",
    "    y10.columns = ['RET']\n",
    "    y15.columns = ['RET']\n",
    "    y20.columns = ['RET']\n",
    "    y25.columns = ['RET']\n",
    "    y30.columns = ['RET']\n",
    "    \n",
    "    y5_b = pd.Series(index=y5.index)\n",
    "    y10_b = pd.Series(index=y5.index)\n",
    "    y15_b = pd.Series(index=y5.index)\n",
    "    y20_b = pd.Series(index=y5.index)\n",
    "    y25_b = pd.Series(index=y5.index)\n",
    "    y30_b = pd.Series(index=y5.index)\n",
    "\n",
    "    y5_b = y5.apply(binary_class)\n",
    "    y10_b = y10.apply(binary_class)\n",
    "    y15_b = y15.apply(binary_class)\n",
    "    y20_b = y20.apply(binary_class)\n",
    "    y25_b = y25.apply(binary_class)\n",
    "    y30_b = y30.apply(binary_class)\n",
    "\n",
    "\n",
    "    y5_t = pd.Series(index=y5.index)\n",
    "    y10_t = pd.Series(index=y5.index)\n",
    "    y15_t = pd.Series(index=y5.index)\n",
    "    y20_t = pd.Series(index=y5.index)\n",
    "    y25_t = pd.Series(index=y5.index)\n",
    "    y30_t = pd.Series(index=y5.index)\n",
    "\n",
    "    y5_t = y5.apply(update_return_class, args=(-0.02, 0.02))\n",
    "    y10_t = y10.apply(update_return_class, args=(-0.03, 0.03))\n",
    "    y15_t = y15.apply(update_return_class, args=(-0.05, 0.05))\n",
    "    y20_t = y20.apply(update_return_class, args=(-0.05, 0.05))\n",
    "    y25_t = y25.apply(update_return_class, args=(-0.05, 0.07))\n",
    "    y30_t = y30.apply(update_return_class, args=(-0.05, 0.08))\n",
    "    \n",
    "    labels = {'binary':{'5b':y5_b,\n",
    "                        '10b':y10_b,\n",
    "                        '15b':y15_b,\n",
    "                        '20b':y20_b,\n",
    "                        '25b':y25_b,\n",
    "                        '30b':y30_b},\n",
    "             'trinary':{'5t':y5_t,\n",
    "                        '10t':y10_t,\n",
    "                        '15t':y15_t,\n",
    "                        '20t':y20_t,\n",
    "                        '25t':y25_t,\n",
    "                        '30t':y30_t}}\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_validation(file_names, scale_model_file, predict_model_file):\n",
    "    scaling_model = joblib.load(scale_model_file)\n",
    "    #prediction_models = joblib.load(predict_model_file)\n",
    "\n",
    "    for file in file_names:\n",
    "        X, labels = get_features_labels(file_names[file])        \n",
    "        for label_type in labels:\n",
    "            for model in labels[label_type]:\n",
    "                print('-------------------------------------------')\n",
    "                print('File:FileNames - %s:%s' %(file,file_names[file]))\n",
    "                print('Label Type: %s' %label_type)\n",
    "                print('Model: %s' %model)\n",
    "                prediction_models = joblib.load(predict_model_files[model])\n",
    "                print('Prediction Model File: %s' %predict_model_files[model])\n",
    "                label_data = labels[label_type][model]\n",
    "                #prediction_saved_model(X, label_data, scaling_model, prediction_models[model])\n",
    "                prediction_saved_model(X, label_data, scaling_model, prediction_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: trinary\n",
      "Model: 20t\n",
      "Prediction Model File: models/20t.mod\n",
      "0.968758416375\n",
      "[[1069   26    0]\n",
      " [  30 1101   30]\n",
      " [   0   30 1427]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.97      1095\n",
      "          1       0.95      0.95      0.95      1161\n",
      "          2       0.98      0.98      0.98      1457\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: trinary\n",
      "Model: 15t\n",
      "Prediction Model File: models/15t.mod\n",
      "0.966334500404\n",
      "[[ 985   25    1]\n",
      " [  25 1331   38]\n",
      " [   1   35 1272]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      1011\n",
      "          1       0.96      0.95      0.96      1394\n",
      "          2       0.97      0.97      0.97      1308\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: trinary\n",
      "Model: 25t\n",
      "Prediction Model File: models/25t.mod\n",
      "0.976030164288\n",
      "[[1109   24    1]\n",
      " [  21 1151   27]\n",
      " [   0   16 1364]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1134\n",
      "          1       0.97      0.96      0.96      1199\n",
      "          2       0.98      0.99      0.98      1380\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: trinary\n",
      "Model: 30t\n",
      "Prediction Model File: models/30t.mod\n",
      "0.978454080259\n",
      "[[1116   23    0]\n",
      " [  23 1137   19]\n",
      " [   0   15 1380]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1139\n",
      "          1       0.97      0.96      0.97      1179\n",
      "          2       0.99      0.99      0.99      1395\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: trinary\n",
      "Model: 5t\n",
      "Prediction Model File: models/5t.mod\n",
      "0.453272286561\n",
      "[[1133   29    0]\n",
      " [ 609  550    0]\n",
      " [  28 1364    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.98      0.77      1162\n",
      "          1       0.28      0.47      0.35      1159\n",
      "          2       0.00      0.00      0.00      1392\n",
      "\n",
      "avg / total       0.29      0.45      0.35      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: trinary\n",
      "Model: 10t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/projects/ml-scikit-learn/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Model File: models/10t.mod\n",
      "0.95663883652\n",
      "[[1090   37    6]\n",
      " [  28 1057   48]\n",
      " [   1   41 1405]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97      1133\n",
      "          1       0.93      0.93      0.93      1133\n",
      "          2       0.96      0.97      0.97      1447\n",
      "\n",
      "avg / total       0.96      0.96      0.96      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: binary\n",
      "Model: 5b\n",
      "Prediction Model File: models/5b.mod\n",
      "0.96337193644\n",
      "[[1690   65]\n",
      " [  71 1887]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96      1755\n",
      "          1       0.97      0.96      0.97      1958\n",
      "\n",
      "avg / total       0.96      0.96      0.96      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: binary\n",
      "Model: 30b\n",
      "Prediction Model File: models/30b.mod\n",
      "0.987072448155\n",
      "[[1541   31]\n",
      " [  17 2124]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98      1572\n",
      "          1       0.99      0.99      0.99      2141\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: binary\n",
      "Model: 10b\n",
      "Prediction Model File: models/10b.mod\n",
      "0.974952868301\n",
      "[[1644   56]\n",
      " [  37 1976]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.97      1700\n",
      "          1       0.97      0.98      0.98      2013\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: binary\n",
      "Model: 20b\n",
      "Prediction Model File: models/20b.mod\n",
      "0.983032588204\n",
      "[[1630   40]\n",
      " [  23 2020]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98      1670\n",
      "          1       0.98      0.99      0.98      2043\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: binary\n",
      "Model: 15b\n",
      "Prediction Model File: models/15b.mod\n",
      "0.975760840291\n",
      "[[1621   50]\n",
      " [  40 2002]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.97      1671\n",
      "          1       0.98      0.98      0.98      2042\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3713\n",
      "\n",
      "-------------------------------------------\n",
      "File:FileNames - file1:data/price_data_68.csv\n",
      "Label Type: binary\n",
      "Model: 25b\n",
      "Prediction Model File: models/25b.mod\n",
      "0.986264476165\n",
      "[[1609   34]\n",
      " [  17 2053]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98      1643\n",
      "          1       0.98      0.99      0.99      2070\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model_validation(test_file, scaling_model_file, predict_model_file)\n",
    "model_validation(test_file, scaling_model_file, '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
